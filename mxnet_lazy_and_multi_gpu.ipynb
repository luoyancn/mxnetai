{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mxnet_lazy_and_multi_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd68a9a0-1120-4d06-8739-8e8ba13b7e7d",
        "id": "qWYlNBUn0SvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/84/d098e0607ee6207448b6af65315f5d45946b49e4f48160eade6cdd64ce4e/mxnet_cu100-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (540.1MB)\n",
            "\u001b[K     |████████████████████████████████| 540.1MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Installing collected packages: mxnet-cu100\n",
            "Successfully installed mxnet-cu100-1.5.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13F6DfzPzPlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "9e9013b7-146a-477c-dcf8-c4b90c14c9ec"
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import nd\n",
        "ctx = mx.gpu()\n",
        "\n",
        "# 延迟执行可以提高程序的性能\n",
        "\n",
        "from time import time\n",
        "\n",
        "start = time()\n",
        "x = nd.random_uniform(shape=(2000, 2000), ctx=ctx)\n",
        "y = nd.dot(x, x) # 并没有真正执行，而是在需要使用的时候再执行\n",
        "\n",
        "print('workloads are queued: %f sec' %(time() - start))\n",
        "print(y)\n",
        "print('workloads are finished: %f sec' %(time() - start))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "workloads are queued: 0.010755 sec\n",
            "\n",
            "[[479.4833  481.7204  499.30383 ... 481.99655 486.93176 495.87143]\n",
            " [479.94864 485.32785 495.4385  ... 495.37183 476.82202 498.1794 ]\n",
            " [492.63098 500.33438 507.08658 ... 494.17532 490.71448 500.85248]\n",
            " ...\n",
            " [492.67075 500.1156  508.92    ... 502.39157 489.79236 510.70807]\n",
            " [480.65863 490.68118 498.50598 ... 487.54398 489.11212 504.79608]\n",
            " [486.09225 496.91916 505.76697 ... 497.94516 486.3714  507.12802]]\n",
            "<NDArray 2000x2000 @gpu(0)>\n",
            "workloads are finished: 0.026173 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e4zoseP2hdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "034746b6-ed4e-43ef-fafd-1713135f4d74"
      },
      "source": [
        "# 如果立即执行的话，需要如下\n",
        "start = time()\n",
        "y = nd.dot(x, x)\n",
        "y.wait_to_read()\n",
        "time() - start"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010281801223754883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F46bZ21_2vM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "e284d697-24a5-4ef3-ca76-1cf6530ada5b"
      },
      "source": [
        "# 或者\n",
        "start = time()\n",
        "y = nd.dot(x, x)\n",
        "z = nd.dot(x, x)\n",
        "nd.waitall()\n",
        "time() - start"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[479.4833  481.7204  499.30383 ... 481.99655 486.93176 495.87143]\n",
              " [479.94864 485.32785 495.4385  ... 495.37183 476.82202 498.1794 ]\n",
              " [492.63098 500.33438 507.08658 ... 494.17532 490.71448 500.85248]\n",
              " ...\n",
              " [492.67075 500.1156  508.92    ... 502.39157 489.79236 510.70807]\n",
              " [480.65863 490.68118 498.50598 ... 487.54398 489.11212 504.79608]\n",
              " [486.09225 496.91916 505.76697 ... 497.94516 486.3714  507.12802]]\n",
              "<NDArray 2000x2000 @gpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKqXlyjQ4CC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "53935505-f3ed-4842-b6eb-0b42811baa4e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 31 03:37:19 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    58W / 149W |    342MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKzO9GNW5Cs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import nd\n",
        "from mxnet import gluon\n",
        "\n",
        "scale = .01\n",
        "w1 = nd.random_normal(shape=(20, 1, 3, 3)) * scale\n",
        "b1 = nd.zeros(shape=20)\n",
        "w2 = nd.random_normal(shape=(50, 20, 5, 5)) * scale\n",
        "b2 = nd.zeros(shape=50)\n",
        "w3 = nd.random_normal(shape=(800, 128)) * scale\n",
        "b3 = nd.zeros(shape=128)\n",
        "w4 = nd.random_normal(shape=(128, 10)) * scale\n",
        "b4 = nd.zeros(shape=10)\n",
        "\n",
        "params = [w1, b1, w2, b2, w3, b3, w4, b4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV3pF_XO6Npt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lenet(x, params):\n",
        "  h1_conv = nd.Convolution(data=x, weight=params[0], bias=params[1], kernel=(3, 3), num_filter=20)\n",
        "  h1_activation = nd.relu(h1_conv)\n",
        "  h1 = nd.Pooling(data=h1_activation, pool_type='avg', kernel=(2, 2), stride=(2, 2))\n",
        "\n",
        "  h2_conv = nd.Convolution(data=h1, weight=params[2], bias=params[3], kernel=(5, 5), num_filter=50)\n",
        "  h2_activation = nd.relu(h2_conv)\n",
        "  h2 = nd.Pooling(data=h2_activation, pool_type='avg', kernel=(2, 2), stride=(2, 2))\n",
        "  h2 = nd.flatten(h2)\n",
        "\n",
        "  h3_linear = nd.dot(h2, params[4]) + params[5]\n",
        "  h3 = nd.relu(h3_linear)\n",
        "\n",
        "  y_hat = nd.dot(h3, params[6]) + params[7]\n",
        "  return y_hat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFy3P8DB7Y-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "677f3b4a-a430-4b8a-865a-bb5207e4d0f9"
      },
      "source": [
        "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "from mxnet import gpu\n",
        "\n",
        "# 将参数分发到GPU上\n",
        "def get_params(params, ctx):\n",
        "  new_params = [p.copyto(ctx) for p in params]\n",
        "  for p in new_params:\n",
        "    p.attach_grad()\n",
        "  return new_params\n",
        "\n",
        "\n",
        "new_params = get_params(params, gpu(0))\n",
        "print('b1 weight=', new_params[1])\n",
        "print('b1 grad=', new_params[1].grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b1 weight= \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "<NDArray 20 @gpu(0)>\n",
            "b1 grad= \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "<NDArray 20 @gpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pfNqwXA8foY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1490bdc4-3a30-4d6f-d569-f53b2b9fb80c"
      },
      "source": [
        "# 给定分布在多个GPU之间的数据， 定义一个函数，将这些数据加起来，然后广播到所有的GPU上\n",
        "\n",
        "def allreduce(data):\n",
        "  for i in range(1, len(data)):\n",
        "    data[0][:] += data[i].copyto(data[0].context)\n",
        "  for i in range(1, len(data)):\n",
        "    data[0].copyto(data[i])\n",
        "\n",
        "\n",
        "data = [nd.ones((1, 2), ctx=gpu(i))*(i+1) for i in range(1)]\n",
        "allreduce(data)\n",
        "print(data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\n",
            "[[1. 1.]]\n",
            "<NDArray 1x2 @gpu(0)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ebuUzPYSJ4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucht9bxtPTI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "9e260123-2ef1-4040-d8e0-23a92a65183f"
      },
      "source": [
        "def split_and_load(data, ctx):\n",
        "  n, k = data.shape[0], len(ctx)\n",
        "  m = n // k\n",
        "  return [data[i*m:(i+1)*m].as_in_context(ctx[i]) for i in range(k)]\n",
        "\n",
        "\n",
        "batch = nd.arange(16).reshape((4, 4))\n",
        "ctx = [gpu(0)]\n",
        "splitted = split_and_load(batch, ctx)\n",
        "print('input: ', batch)\n",
        "print('load into', ctx)\n",
        "print('output: ', splitted)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:  \n",
            "[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "<NDArray 4x4 @cpu(0)>\n",
            "load into [gpu(0)]\n",
            "output:  [\n",
            "[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "<NDArray 4x4 @gpu(0)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZpDFAIBRs8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import autograd\n",
        "\n",
        "import utils\n",
        "\n",
        "\n",
        "def train_batch(data, label, params, ctx, lr):\n",
        "  data_list = split_and_load(data, ctx)\n",
        "  label_list = split_and_load(label, ctx)\n",
        "  with autograd.record():\n",
        "    losses = [loss(lenet(x, w), y) for x, y, w in zip(data_list, label_list, params)]\n",
        "  for l in losses:\n",
        "    l.backward()\n",
        "  for i in range(len(params[0])):\n",
        "    allreduce([params[c][i].grad for c in range(len(ctx))])\n",
        "  for p in params:\n",
        "    utils.SGD(p, lr/data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqPOAl-iWXX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "def train(num_gpus, batch_size, lr):\n",
        "  train_data, test_data = utils.load_data_fashion_mnist_new(batch_size=batch_size)\n",
        "  ctx = [gpu(i) for i in range(num_gpus)]\n",
        "  dev_params = [get_params(params, c) for c in ctx]\n",
        "  for epoch in range(5):\n",
        "    start = time()\n",
        "    for data, label in train_data:\n",
        "      train_batch(data, label, dev_params, ctx, lr)\n",
        "    nd.waitall()\n",
        "    print('Epoch %d, training time = %f sec' %(epoch, time() - start))\n",
        "    net = lambda data: lenet(data, dev_params[0])\n",
        "    test_acc = utils.evaluate_accuracy(test_data, net, ctx[0])\n",
        "    print('     validatioin accuracy = %f' %(test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjd4J6k4XXA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "a22d7930-8e3c-4ce2-c499-db5807664a54"
      },
      "source": [
        "train(1, 256, 0.3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, training time = 2.574747 sec\n",
            "     validatioin accuracy = 0.100060\n",
            "Epoch 1, training time = 2.458804 sec\n",
            "     validatioin accuracy = 0.737179\n",
            "Epoch 2, training time = 2.442271 sec\n",
            "     validatioin accuracy = 0.790765\n",
            "Epoch 3, training time = 2.441624 sec\n",
            "     validatioin accuracy = 0.782953\n",
            "Epoch 4, training time = 2.462935 sec\n",
            "     validatioin accuracy = 0.825921\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}